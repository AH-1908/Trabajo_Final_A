{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b53f2a4-9fa1-4046-8290-f5c9d6889408",
   "metadata": {},
   "source": [
    "<center><h1><span style=\"\">Universidad Nacional Agraria La Molina</span></h1></center>\n",
    "<center><h2><span style=\"\">Estadística Infórmatica</span></h2></center>\n",
    "\n",
    "<center><img src=\"escudo1.jpg\" width=\"300\" height=\"200\"></center>\n",
    "\n",
    "<center><h4><span style=\"\">Curso: Lenguaje de Programación II</span></h4></center>\n",
    "<center><h3><span style=\"\"> <b>Proyecto: <i></b></i></span></h3></center>\n",
    "\n",
    "<center><h3><span style=\"\">Profesora: Dra. Ana Cecilia Vargas Paredes</span></h3></center>\n",
    "\n",
    "### Integrantes: \n",
    "\n",
    "1. Mandujano Cortez Anthony Luis 20220769\n",
    "2. Puma Centeno Katia Lee 20221414\n",
    "3. Asencios Menacho Soledad 20221390\n",
    "\n",
    "## Introducción\n",
    "\n",
    "Este proyecto tiene como objetivo analizar las tendencias musicales en las siguientes plataformas de streaming de música: Spotify, YouTube y Shazam. Mediante el uso de las APIs y técnicas de web scraping de estas plataformas, se recopilarán datos sobre las canciones más escuchadas, artistas más populares y otros indicadores relevantes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4fb5ad-fbd9-489e-bc86-43dd663f8a2f",
   "metadata": {},
   "source": [
    "## Objetivos del proyecto\n",
    "1. Identificar las canciones y artistas más populares en cada plataforma: Se analizará el volumen de reproducciones, descargas, búsquedas y agregaciones a playlists para determinar las tendencias musicales más destacadas en cada plataforma.\n",
    "2. Comparar las tendencias musicales entre plataformas: Se compararán los resultados obtenidos en cada plataforma para identificar similitudes, diferencias y patrones únicos en las preferencias musicales de los usuarios.\n",
    "3. Analizar la evolución de las tendencias musicales a lo largo del tiempo: Se realizará un seguimiento de las tendencias musicales durante un período determinado para identificar cambios en las preferencias de los usuarios y la aparición de nuevos artistas o géneros.\n",
    "4. Visualizar los resultados de manera atractiva y comprensible: Se utilizarán gráficos, tablas y otras herramientas de visualización para presentar los resultados de manera clara y accesible a una audiencia amplia.\n",
    "\n",
    "## Producto Final:\n",
    "1. Un resumen de las principales tendencias musicales en cada plataforma de streaming.\n",
    "2. Una comparación detallada de las tendencias entre las diferentes plataformas.\n",
    "3. Un análisis de la evolución de las tendencias musicales a lo largo del tiempo.\n",
    "4. Visualizaciones atractivas que representen los datos de manera clara y concisa.\n",
    "5. Conclusiones y recomendaciones sobre el futuro de la industria musical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac1bacf",
   "metadata": {},
   "source": [
    "# Extración de información \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2155367",
   "metadata": {},
   "source": [
    "## Descarga automatizada del csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "378f0c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-api-python-client\n",
      "  Obtaining dependency information for google-api-python-client from https://files.pythonhosted.org/packages/ca/64/ea07e135989a7c4b7c3f12560f0660009b43f82df5954fdec93243744d5b/google_api_python_client-2.137.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_api_python_client-2.137.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client)\n",
      "  Obtaining dependency information for httplib2<1.dev0,>=0.19.0 from https://files.pythonhosted.org/packages/a8/6c/d2fbdaaa5959339d53ba38e94c123e4e84b8fbc4b84beb0e70d7c1608486/httplib2-0.22.0-py3-none-any.whl.metadata\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 (from google-api-python-client)\n",
      "  Obtaining dependency information for google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 from https://files.pythonhosted.org/packages/e7/00/85c22f7f73fa2e88dfbf0e1f63c565386ba40e0264b59c8a4362ae27c9fc/google_auth-2.32.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth-2.32.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client)\n",
      "  Obtaining dependency information for google-auth-httplib2<1.0.0,>=0.2.0 from https://files.pythonhosted.org/packages/be/8a/fe34d2f3f9470a27b01c9e76226965863f153d5fbe276f83608562e49c04/google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 (from google-api-python-client)\n",
      "  Obtaining dependency information for google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 from https://files.pythonhosted.org/packages/44/99/daa3541e8ecd7d8b7907b714ba92126097a976b5b3dbabdb5febdcf08554/google_api_core-2.19.1-py3-none-any.whl.metadata\n",
      "  Downloading google_api_core-2.19.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client)\n",
      "  Obtaining dependency information for uritemplate<5,>=3.0.1 from https://files.pythonhosted.org/packages/81/c0/7461b49cd25aeece13766f02ee576d1db528f1c37ce69aee300e075b485b/uritemplate-4.1.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client)\n",
      "  Obtaining dependency information for googleapis-common-protos<2.0.dev0,>=1.56.2 from https://files.pythonhosted.org/packages/02/48/87422ff1bddcae677fb6f58c97f5cfc613304a5e8ce2c3662760199c0a84/googleapis_common_protos-1.63.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client)\n",
      "  Obtaining dependency information for protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 from https://files.pythonhosted.org/packages/b1/04/73b8fd7f34f3a2b2b64aa31a173b8aebbdb0c55523df4c027846bb44bc1e/protobuf-5.27.2-cp310-abi3-win_amd64.whl.metadata\n",
      "  Downloading protobuf-5.27.2-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client)\n",
      "  Obtaining dependency information for proto-plus<2.0.0dev,>=1.22.3 from https://files.pythonhosted.org/packages/7c/6f/db31f0711c0402aa477257205ce7d29e86a75cb52cd19f7afb585f75cda0/proto_plus-1.24.0-py3-none-any.whl.metadata\n",
      "  Downloading proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\mandu\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.31.0)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client)\n",
      "  Obtaining dependency information for cachetools<6.0,>=2.0.0 from https://files.pythonhosted.org/packages/fb/2b/a64c2d25a37aeb921fddb929111413049fc5f8b9a4c1aefaffaafe768d54/cachetools-5.3.3-py3-none-any.whl.metadata\n",
      "  Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\mandu\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client)\n",
      "  Obtaining dependency information for rsa<5,>=3.1.4 from https://files.pythonhosted.org/packages/49/97/fa78e3d2f65c02c8e1268b9aba606569fe97f6c8f7c2d74394553347c145/rsa-4.9-py3-none-any.whl.metadata\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\mandu\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\mandu\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mandu\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mandu\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mandu\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mandu\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2024.2.2)\n",
      "Downloading google_api_python_client-2.137.0-py2.py3-none-any.whl (12.0 MB)\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/12.0 MB 4.6 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.3/12.0 MB 3.8 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.3/12.0 MB 2.3 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.6/12.0 MB 2.9 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.7/12.0 MB 2.7 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.7/12.0 MB 2.7 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.7/12.0 MB 2.7 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.9/12.0 MB 2.3 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 1.1/12.0 MB 2.6 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 1.1/12.0 MB 2.5 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.3/12.0 MB 2.5 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.4/12.0 MB 2.5 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.5/12.0 MB 2.5 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.6/12.0 MB 2.5 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.8/12.0 MB 2.5 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.8/12.0 MB 2.5 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.8/12.0 MB 2.5 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.9/12.0 MB 2.2 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 2.1/12.0 MB 2.3 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 2.2/12.0 MB 2.3 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 2.3/12.0 MB 2.3 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.4/12.0 MB 2.3 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.5/12.0 MB 2.3 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.6/12.0 MB 2.3 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.7/12.0 MB 2.3 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.7/12.0 MB 2.2 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 2.9/12.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 3.0/12.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 3.1/12.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 3.2/12.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.3/12.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 3.6/12.0 MB 2.1 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 3.7/12.0 MB 2.1 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 3.8/12.0 MB 2.1 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 4.0/12.0 MB 2.2 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 4.1/12.0 MB 2.1 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 4.2/12.0 MB 2.2 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 4.2/12.0 MB 2.2 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 4.2/12.0 MB 2.2 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 4.2/12.0 MB 2.2 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 4.2/12.0 MB 2.2 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 4.3/12.0 MB 2.0 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 4.5/12.0 MB 2.0 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 4.6/12.0 MB 2.0 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 4.7/12.0 MB 2.0 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 4.8/12.0 MB 2.0 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 4.9/12.0 MB 2.0 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 5.1/12.0 MB 2.0 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 5.2/12.0 MB 2.1 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 5.3/12.0 MB 2.1 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 5.4/12.0 MB 2.1 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 5.5/12.0 MB 2.1 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 5.6/12.0 MB 2.1 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 5.6/12.0 MB 2.1 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 5.8/12.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 6.0/12.0 MB 2.1 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 6.0/12.0 MB 2.1 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 6.1/12.0 MB 2.1 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 6.2/12.0 MB 2.1 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 6.3/12.0 MB 2.1 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 6.4/12.0 MB 2.1 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 6.6/12.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 6.6/12.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 6.7/12.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 6.9/12.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 7.0/12.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 7.1/12.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 7.2/12.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 7.2/12.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 7.4/12.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 7.5/12.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 7.5/12.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 7.5/12.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 7.5/12.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 7.5/12.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 7.5/12.0 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 7.6/12.0 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 7.7/12.0 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 7.8/12.0 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 7.9/12.0 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.1/12.0 MB 2.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.2/12.0 MB 2.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.2/12.0 MB 2.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.2/12.0 MB 2.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.2/12.0 MB 2.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.2/12.0 MB 2.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.2/12.0 MB 2.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.3/12.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.4/12.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.5/12.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.6/12.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.7/12.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.8/12.0 MB 2.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.9/12.0 MB 2.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.9/12.0 MB 2.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.9/12.0 MB 2.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.9/12.0 MB 2.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.9/12.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 9.1/12.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 9.2/12.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 9.3/12.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 9.4/12.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 9.5/12.0 MB 1.9 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 9.6/12.0 MB 1.9 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 9.7/12.0 MB 1.9 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 9.8/12.0 MB 1.9 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 9.8/12.0 MB 1.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 10.0/12.0 MB 1.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 10.0/12.0 MB 1.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 10.2/12.0 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.3/12.0 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.4/12.0 MB 1.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.5/12.0 MB 1.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.5/12.0 MB 1.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.5/12.0 MB 1.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.5/12.0 MB 1.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.5/12.0 MB 1.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.5/12.0 MB 1.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.6/12.0 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.8/12.0 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.9/12.0 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.9/12.0 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.0/12.0 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.2/12.0 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.3/12.0 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.4/12.0 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.5/12.0 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.5/12.0 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.5/12.0 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.5/12.0 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.5/12.0 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.6/12.0 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.8/12.0 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.8/12.0 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.9/12.0 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.0/12.0 MB 1.8 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.19.1-py3-none-any.whl (139 kB)\n",
      "   ---------------------------------------- 0.0/139.4 kB ? eta -:--:--\n",
      "   ----------------------------- ---------- 102.4/139.4 kB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 139.4/139.4 kB 1.7 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.32.0-py2.py3-none-any.whl (195 kB)\n",
      "   ---------------------------------------- 0.0/195.5 kB ? eta -:--:--\n",
      "   ----------------------------------- ---- 174.1/195.5 kB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 195.5/195.5 kB 3.9 MB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "   ---------------------------------------- 0.0/96.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 96.9/96.9 kB 2.8 MB/s eta 0:00:00\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl (220 kB)\n",
      "   ---------------------------------------- 0.0/220.0 kB ? eta -:--:--\n",
      "   -------------------- ------------------- 112.6/220.0 kB 3.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 112.6/220.0 kB 3.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 112.6/220.0 kB 3.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 112.6/220.0 kB 3.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 112.6/220.0 kB 3.3 MB/s eta 0:00:01\n",
      "   ------------------------ ------------- 143.4/220.0 kB 500.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- 220.0/220.0 kB 746.5 kB/s eta 0:00:00\n",
      "Downloading proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.1/50.1 kB ? eta 0:00:00\n",
      "Downloading protobuf-5.27.2-cp310-abi3-win_amd64.whl (426 kB)\n",
      "   ---------------------------------------- 0.0/426.9 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 174.1/426.9 kB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 276.5/426.9 kB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 368.6/426.9 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 426.9/426.9 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Installing collected packages: uritemplate, rsa, protobuf, httplib2, cachetools, proto-plus, googleapis-common-protos, google-auth, google-auth-httplib2, google-api-core, google-api-python-client\n",
      "Successfully installed cachetools-5.3.3 google-api-core-2.19.1 google-api-python-client-2.137.0 google-auth-2.32.0 google-auth-httplib2-0.2.0 googleapis-common-protos-1.63.2 httplib2-0.22.0 proto-plus-1.24.0 protobuf-5.27.2 rsa-4.9 uritemplate-4.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-api-python-client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cee6c7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Proceso para Obtener y Almacenar las Tendencias Musicales de YouTube\n",
    "\n",
    "Este script interactúa con la API de YouTube para obtener las 50 tendencias musicales principales en varios países y almacenar la información en una base de datos SQLite y archivos CSV. Las principales funcionalidades incluyen autenticación en YouTube, creación de tablas en SQLite, y exportación de datos a CSV.\n",
    "\n",
    "### Importación de Módulos\n",
    "\n",
    "```python\n",
    "import csv\n",
    "import os\n",
    "from googleapiclient.discovery import build\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "```\n",
    "\n",
    "Se importan las siguientes bibliotecas:\n",
    "- `csv`: Para manejar operaciones con archivos CSV.\n",
    "- `os`: Para realizar operaciones del sistema, como la creación de directorios.\n",
    "- `googleapiclient.discovery`: Biblioteca para interactuar con la API de YouTube.\n",
    "- `sqlite3`: Para manejar una base de datos SQLite.\n",
    "- `datetime`: Para manejar y formatear fechas.\n",
    "\n",
    "### Funciones\n",
    "\n",
    "#### 1. Obtener las Top 30 Tendencias Musicales de YouTube en un País\n",
    "\n",
    "```python\n",
    "def obtener_top_tendencias(api_key, region_code):\n",
    "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "    \n",
    "    request = youtube.videos().list(\n",
    "        part='snippet,statistics',\n",
    "        chart='mostPopular',\n",
    "        regionCode=region_code,\n",
    "        videoCategoryId='10',  # Categoría de música\n",
    "        maxResults=50\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    tendencias = []\n",
    "    for index, item in enumerate(response['items'], start=1):\n",
    "        fecha_publicacion = item['snippet']['publishedAt']\n",
    "        try:\n",
    "            fecha_publicacion = datetime.strptime(fecha_publicacion, '%Y-%m-%dT%H:%M:%SZ').date()\n",
    "        except ValueError:\n",
    "            fecha_publicacion = None  # Si no se puede convertir, dejar como None\n",
    "\n",
    "        tendencia = {\n",
    "            'titulo': item['snippet']['title'],\n",
    "            'canal': item['snippet']['channelTitle'],\n",
    "            'posicion': index,\n",
    "            'fecha_subida': datetime.now().date(),\n",
    "            'fecha_publicacion': fecha_publicacion,\n",
    "            'vistas': int(item['statistics'].get('viewCount', 0))\n",
    "        }\n",
    "        tendencias.append(tendencia)\n",
    "\n",
    "    return tendencias\n",
    "```\n",
    "\n",
    "Esta función realiza las siguientes tareas:\n",
    "1. Se autentica en la API de YouTube usando `googleapiclient`.\n",
    "2. Obtiene las 50 tendencias musicales principales en una región específica.\n",
    "3. Procesa y devuelve una lista de diccionarios con información sobre cada tendencia.\n",
    "\n",
    "#### 2. Crear una Tabla en SQLite\n",
    "\n",
    "```python\n",
    "def crear_tabla(pais):\n",
    "    conn = sqlite3.connect('youtube.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        cursor.execute(f'''\n",
    "            CREATE TABLE IF NOT EXISTS top_tendencias_{pais} (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                titulo TEXT,\n",
    "                canal TEXT,\n",
    "                posicion INTEGER,\n",
    "                fecha_subida DATE,\n",
    "                fecha_publicacion DATE,\n",
    "                vistas INTEGER\n",
    "            )\n",
    "        ''')\n",
    "        conn.commit()\n",
    "        print(f\"Tabla 'top_tendencias_{pais}' creada correctamente en SQLite.\")\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Error al crear la tabla: {e}\")\n",
    "\n",
    "    conn.close()\n",
    "```\n",
    "\n",
    "Esta función:\n",
    "1. Conecta a una base de datos SQLite llamada `youtube.db`.\n",
    "2. Crea una tabla con un nombre basado en el país, si no existe.\n",
    "3. Define los campos de la tabla: id, título, canal, posición, fecha de subida, fecha de publicación, vistas.\n",
    "4. Maneja posibles errores en la creación de la tabla.\n",
    "\n",
    "#### 3. Almacenar las Tendencias en SQLite\n",
    "\n",
    "```python\n",
    "def almacenar_en_sqlite(tendencias, pais):\n",
    "    conn = sqlite3.connect('youtube.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        for tendencia in tendencias:\n",
    "            cursor.execute(f'''\n",
    "                INSERT INTO top_tendencias_{pais}(titulo, canal, posicion, fecha_subida, fecha_publicacion, vistas)\n",
    "                VALUES (?, ?, ?, ?, ?, ?)\n",
    "            ''', (tendencia['titulo'], tendencia['canal'], tendencia['posicion'], tendencia['fecha_subida'], tendencia['fecha_publicacion'], tendencia['vistas']))\n",
    "\n",
    "        conn.commit()\n",
    "        print(f\"Datos almacenados correctamente en SQLite para {pais}.\")\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Error al insertar datos: {e}\")\n",
    "\n",
    "    conn.close()\n",
    "```\n",
    "\n",
    "Esta función:\n",
    "1. Conecta a la base de datos SQLite.\n",
    "2. Inserta cada tendencia en la tabla correspondiente.\n",
    "3. Maneja posibles errores en la inserción de datos.\n",
    "\n",
    "#### 4. Almacenar las Tendencias en un Archivo CSV\n",
    "\n",
    "```python\n",
    "def almacenar_en_csv(tendencias, pais):\n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "\n",
    "    csv_filename = f'data/top_tendencias_{pais}.csv'\n",
    "\n",
    "    with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['titulo', 'canal', 'posicion', 'fecha_subida', 'fecha_publicacion', 'vistas']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for tendencia in tendencias:\n",
    "            writer.writerow(tendencia)\n",
    "\n",
    "    print(f\"Datos almacenados correctamente en '{csv_filename}' para {pais}.\")\n",
    "```\n",
    "\n",
    "Esta función:\n",
    "1. Crea un directorio `data` si no existe.\n",
    "2. Crea y abre un archivo CSV para escribir los datos.\n",
    "3. Escribe los encabezados y la información de cada tendencia en el archivo CSV.\n",
    "\n",
    "#### 5. Leer los Códigos de Región de los Países\n",
    "\n",
    "```python\n",
    "def leer_ids_pais(filename):\n",
    "    ids_pais = {}\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            if \"=\" in line:\n",
    "                pais, region_code = line.strip().split(\" = \")\n",
    "                ids_pais[pais.strip()] = region_code.strip()\n",
    "    return ids_pais\n",
    "```\n",
    "\n",
    "Esta función:\n",
    "1. Lee un archivo con códigos de región por país.\n",
    "2. Devuelve un diccionario donde las claves son los nombres de los países y los valores son los códigos de región.\n",
    "\n",
    "### Ejecución del Script\n",
    "\n",
    "```python\n",
    "if __name__ == '__main__':\n",
    "    api_key = 'AIzaSyC88xiUVHfPJQ0Z7NvQ57l50kAhytxkDt4'  # Reemplaza con tu clave de API de YouTube\n",
    "    ids_pais = leer_ids_pais('ID_Pais_yt.txt')\n",
    "\n",
    "    for pais, region_code in ids_pais.items():\n",
    "        crear_tabla(pais)\n",
    "        tendencias = obtener_top_tendencias(api_key, region_code)\n",
    "        almacenar_en_sqlite(tendencias, pais)\n",
    "        almacenar_en_csv(tendencias, pais)\n",
    "```\n",
    "\n",
    "Este bloque de código:\n",
    "1. Lee los códigos de región desde el archivo `ID_Pais_yt.txt`.\n",
    "2. Para cada país:\n",
    "    - Crea una tabla en SQLite.\n",
    "    - Obtiene las top tendencias musicales de la región correspondiente.\n",
    "    - Almacena las tendencias en la base de datos SQLite.\n",
    "    - Exporta las tendencias a un archivo CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c14bf49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla 'top_tendencias_Perú' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Perú.\n",
      "Datos almacenados correctamente en 'data/top_tendencias_Perú.csv' para Perú.\n",
      "Tabla 'top_tendencias_Colombia' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Colombia.\n",
      "Datos almacenados correctamente en 'data/top_tendencias_Colombia.csv' para Colombia.\n",
      "Tabla 'top_tendencias_Argentina' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Argentina.\n",
      "Datos almacenados correctamente en 'data/top_tendencias_Argentina.csv' para Argentina.\n",
      "Tabla 'top_tendencias_Brasil' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Brasil.\n",
      "Datos almacenados correctamente en 'data/top_tendencias_Brasil.csv' para Brasil.\n",
      "Tabla 'top_tendencias_Chile' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Chile.\n",
      "Datos almacenados correctamente en 'data/top_tendencias_Chile.csv' para Chile.\n",
      "Tabla 'top_tendencias_México' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para México.\n",
      "Datos almacenados correctamente en 'data/top_tendencias_México.csv' para México.\n",
      "Tabla 'top_tendencias_Uruguay' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Uruguay.\n",
      "Datos almacenados correctamente en 'data/top_tendencias_Uruguay.csv' para Uruguay.\n",
      "Tabla 'top_tendencias_Venezuela' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Venezuela.\n",
      "Datos almacenados correctamente en 'data/top_tendencias_Venezuela.csv' para Venezuela.\n",
      "Tabla 'top_tendencias_Ecuador' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Ecuador.\n",
      "Datos almacenados correctamente en 'data/top_tendencias_Ecuador.csv' para Ecuador.\n",
      "Tabla 'top_tendencias_Puerto_Rico' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Puerto_Rico.\n",
      "Datos almacenados correctamente en 'data/top_tendencias_Puerto_Rico.csv' para Puerto_Rico.\n",
      "Tabla 'top_tendencias_Estados_Unidos' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Estados_Unidos.\n",
      "Datos almacenados correctamente en 'data/top_tendencias_Estados_Unidos.csv' para Estados_Unidos.\n",
      "Tabla 'top_tendencias_Reino_Unido' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Reino_Unido.\n",
      "Datos almacenados correctamente en 'data/top_tendencias_Reino_Unido.csv' para Reino_Unido.\n",
      "Tabla 'top_tendencias_Japón' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Japón.\n",
      "Datos almacenados correctamente en 'data/top_tendencias_Japón.csv' para Japón.\n",
      "Tabla 'top_tendencias_Corea_del_Sur' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Corea_del_Sur.\n",
      "Datos almacenados correctamente en 'data/top_tendencias_Corea_del_Sur.csv' para Corea_del_Sur.\n",
      "Tabla 'top_tendencias_Francia' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Francia.\n",
      "Datos almacenados correctamente en 'data/top_tendencias_Francia.csv' para Francia.\n",
      "Tabla 'top_tendencias_Alemania' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Alemania.\n",
      "Datos almacenados correctamente en 'data/top_tendencias_Alemania.csv' para Alemania.\n",
      "Tabla 'top_tendencias_Australia' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Australia.\n",
      "Datos almacenados correctamente en 'data/top_tendencias_Australia.csv' para Australia.\n",
      "Tabla 'top_tendencias_Canadá' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Canadá.\n",
      "Datos almacenados correctamente en 'data/top_tendencias_Canadá.csv' para Canadá.\n",
      "Tabla 'top_tendencias_India' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para India.\n",
      "Datos almacenados correctamente en 'data/top_tendencias_India.csv' para India.\n",
      "Tabla 'top_tendencias_España' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para España.\n",
      "Datos almacenados correctamente en 'data/top_tendencias_España.csv' para España.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "from googleapiclient.discovery import build\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "# Función para obtener las top 50 tendencias musicales de YouTube en un país\n",
    "def obtener_top_tendencias(api_key, region_code):\n",
    "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "    \n",
    "    # Llamada a la API para obtener las tendencias\n",
    "    request = youtube.videos().list(\n",
    "        part='snippet,statistics',\n",
    "        chart='mostPopular',\n",
    "        regionCode=region_code,\n",
    "        videoCategoryId='10',  # Categoría de música\n",
    "        maxResults=50\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    # Preparar los datos para la base de datos\n",
    "    tendencias = []\n",
    "    for index, item in enumerate(response['items'], start=1):\n",
    "        # Obtener la fecha de publicación del video\n",
    "        fecha_publicacion = item['snippet']['publishedAt']\n",
    "        try:\n",
    "            fecha_publicacion = datetime.strptime(fecha_publicacion, '%Y-%m-%dT%H:%M:%SZ').date()\n",
    "        except ValueError:\n",
    "            fecha_publicacion = None  # Si no se puede convertir, dejar como None\n",
    "\n",
    "        # Crear el diccionario de la tendencia\n",
    "        tendencia = {\n",
    "            'titulo': item['snippet']['title'],\n",
    "            'canal': item['snippet']['channelTitle'],\n",
    "            'posicion': index,\n",
    "            'fecha_subida': datetime.now().date(),\n",
    "            'fecha_publicacion': fecha_publicacion,\n",
    "            'vistas': int(item['statistics'].get('viewCount', 0))\n",
    "        }\n",
    "        tendencias.append(tendencia)\n",
    "\n",
    "    return tendencias\n",
    "\n",
    "# Función para crear una tabla en SQLite\n",
    "def crear_tabla(pais):\n",
    "    conn = sqlite3.connect('youtube.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        # Crear la tabla si no existe\n",
    "        cursor.execute(f'''\n",
    "            CREATE TABLE IF NOT EXISTS top_tendencias_{pais} (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                titulo TEXT,\n",
    "                canal TEXT,\n",
    "                posicion INTEGER,\n",
    "                fecha_subida DATE,\n",
    "                fecha_publicacion DATE,\n",
    "                vistas INTEGER\n",
    "            )\n",
    "        ''')\n",
    "        conn.commit()\n",
    "        print(f\"Tabla 'top_tendencias_{pais}' creada correctamente en SQLite.\")\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Error al crear la tabla: {e}\")\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "# Función para almacenar las tendencias en SQLite\n",
    "def almacenar_en_sqlite(tendencias, pais):\n",
    "    conn = sqlite3.connect('youtube.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        # Insertar las tendencias en la tabla\n",
    "        for tendencia in tendencias:\n",
    "            cursor.execute(f'''\n",
    "                INSERT INTO top_tendencias_{pais}(titulo, canal, posicion, fecha_subida, fecha_publicacion, vistas)\n",
    "                VALUES (?, ?, ?, ?, ?, ?)\n",
    "            ''', (tendencia['titulo'], tendencia['canal'], tendencia['posicion'], tendencia['fecha_subida'], tendencia['fecha_publicacion'], tendencia['vistas']))\n",
    "\n",
    "        conn.commit()\n",
    "        print(f\"Datos almacenados correctamente en SQLite para {pais}.\")\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Error al insertar datos: {e}\")\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "# Función para almacenar las tendencias en un archivo CSV dentro de la carpeta 'data'\n",
    "def almacenar_en_csv(tendencias, pais):\n",
    "    # Crear la carpeta 'data' si no existe\n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "\n",
    "    csv_filename = f'data/top_tendencias_{pais}.csv'\n",
    "\n",
    "    with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['titulo', 'canal', 'posicion', 'fecha_subida', 'fecha_publicacion', 'vistas']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for tendencia in tendencias:\n",
    "            writer.writerow(tendencia)\n",
    "\n",
    "    print(f\"Datos almacenados correctamente en '{csv_filename}' para {pais}.\")\n",
    "\n",
    "# Función para leer los IDs de los países\n",
    "def leer_ids_pais(filename):\n",
    "    ids_pais = {}\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            if \"=\" in line:\n",
    "                pais, region_code = line.strip().split(\" = \")\n",
    "                ids_pais[pais.strip()] = region_code.strip()\n",
    "    return ids_pais\n",
    "\n",
    "# Ejemplo de uso\n",
    "if __name__ == '__main__':\n",
    "    api_key = 'AIzaSyC88xiUVHfPJQ0Z7NvQ57l50kAhytxkDt4'  # Reemplaza con tu clave de API de YouTube\n",
    "    ids_pais = leer_ids_pais('ID_Pais_yt.txt')\n",
    "\n",
    "    for pais, region_code in ids_pais.items():\n",
    "        crear_tabla(pais)\n",
    "        tendencias = obtener_top_tendencias(api_key, region_code)\n",
    "        almacenar_en_sqlite(tendencias, pais)\n",
    "        almacenar_en_csv(tendencias, pais)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5cb5ea",
   "metadata": {},
   "source": [
    "\n",
    "## Proceso para Obtener y Almacenar las Top Canciones de Spotify\n",
    "\n",
    "Este script está diseñado para interactuar con la API de Spotify, obtener las 50 canciones principales de varias playlists y almacenar la información en una base de datos SQLite y archivos CSV. La funcionalidad principal incluye la autenticación en Spotify, la creación de tablas en SQLite, y la exportación de datos a CSV.\n",
    "\n",
    "### Importación de Módulos\n",
    "\n",
    "```python\n",
    "import csv\n",
    "import os\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "```\n",
    "\n",
    "Se importan las siguientes bibliotecas:\n",
    "- `csv`: Para manejar operaciones con archivos CSV.\n",
    "- `os`: Para realizar operaciones del sistema, como la creación de directorios.\n",
    "- `spotipy`: Biblioteca para interactuar con la API de Spotify.\n",
    "- `SpotifyClientCredentials`: Clase para autenticarse con la API de Spotify usando credenciales.\n",
    "- `sqlite3`: Para manejar una base de datos SQLite.\n",
    "- `datetime`: Para manejar y formatear fechas.\n",
    "\n",
    "### Funciones\n",
    "\n",
    "#### 1. Obtener las Top 50 Canciones de una Playlist en Spotify\n",
    "\n",
    "```python\n",
    "def obtener_top_canciones(playlist_id):\n",
    "    with open('spotify_credentials.txt') as f:\n",
    "        lines = f.readlines()\n",
    "        client_id = lines[0].strip()\n",
    "        client_secret = lines[1].strip()\n",
    "\n",
    "    client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "    sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "    playlist = sp.playlist_tracks(playlist_id=playlist_id, limit=50)\n",
    "\n",
    "    canciones = []\n",
    "    for index, track in enumerate(playlist['items'], start=1):\n",
    "        fecha_lanzamiento = track['track']['album']['release_date']\n",
    "        try:\n",
    "            fecha_lanzamiento = datetime.strptime(fecha_lanzamiento, '%Y-%m-%d').date()\n",
    "        except ValueError:\n",
    "            try:\n",
    "                fecha_lanzamiento = datetime.strptime(fecha_lanzamiento, '%Y').date()\n",
    "            except ValueError:\n",
    "                fecha_lanzamiento = None\n",
    "\n",
    "        cancion = {\n",
    "            'nombre': track['track']['name'],\n",
    "            'artista': track['track']['artists'][0]['name'],\n",
    "            'posicion': index,\n",
    "            'fecha_subida': datetime.now().date(),\n",
    "            'fecha_lanzamiento': fecha_lanzamiento,\n",
    "            'reproducciones': track['track']['popularity']\n",
    "        }\n",
    "        canciones.append(cancion)\n",
    "\n",
    "    return canciones\n",
    "```\n",
    "\n",
    "Esta función realiza las siguientes tareas:\n",
    "1. Lee las credenciales de Spotify desde un archivo `spotify_credentials.txt`.\n",
    "2. Se autentica en la API de Spotify usando `spotipy`.\n",
    "3. Obtiene las 50 canciones principales de una playlist específica.\n",
    "4. Procesa y devuelve una lista de diccionarios con información sobre cada canción.\n",
    "\n",
    "#### 2. Crear una Tabla en SQLite\n",
    "\n",
    "```python\n",
    "def crear_tabla(pais):\n",
    "    conn = sqlite3.connect('spotify.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        cursor.execute(f'''\n",
    "            CREATE TABLE IF NOT EXISTS top_canciones_{pais} (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                nombre TEXT,\n",
    "                artista TEXT,\n",
    "                posicion INTEGER,\n",
    "                fecha_subida DATE,\n",
    "                fecha_lanzamiento DATE,\n",
    "                reproducciones INTEGER\n",
    "            )\n",
    "        ''')\n",
    "        conn.commit()\n",
    "        print(f\"Tabla 'top_canciones_{pais}' creada correctamente en SQLite.\")\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Error al crear la tabla: {e}\")\n",
    "\n",
    "    conn.close()\n",
    "```\n",
    "\n",
    "Esta función:\n",
    "1. Conecta a una base de datos SQLite llamada `spotify.db`.\n",
    "2. Crea una tabla con un nombre basado en el país, si no existe.\n",
    "3. Define los campos de la tabla: id, nombre, artista, posición, fecha de subida, fecha de lanzamiento, reproducciones.\n",
    "4. Maneja posibles errores en la creación de la tabla.\n",
    "\n",
    "#### 3. Almacenar las Canciones en SQLite\n",
    "\n",
    "```python\n",
    "def almacenar_en_sqlite(canciones, pais):\n",
    "    conn = sqlite3.connect('spotify.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        for cancion in canciones:\n",
    "            cursor.execute(f'''\n",
    "                INSERT INTO top_canciones_{pais}(nombre, artista, posicion, fecha_subida, fecha_lanzamiento, reproducciones)\n",
    "                VALUES (?, ?, ?, ?, ?, ?)\n",
    "            ''', (cancion['nombre'], cancion['artista'], cancion['posicion'], cancion['fecha_subida'], cancion['fecha_lanzamiento'], cancion['reproducciones']))\n",
    "\n",
    "        conn.commit()\n",
    "        print(f\"Datos almacenados correctamente en SQLite para {pais}.\")\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Error al insertar datos: {e}\")\n",
    "\n",
    "    conn.close()\n",
    "```\n",
    "\n",
    "Esta función:\n",
    "1. Conecta a la base de datos SQLite.\n",
    "2. Inserta cada canción en la tabla correspondiente.\n",
    "3. Maneja posibles errores en la inserción de datos.\n",
    "\n",
    "#### 4. Almacenar las Canciones en un Archivo CSV\n",
    "\n",
    "```python\n",
    "def almacenar_en_csv(canciones, pais):\n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "\n",
    "    csv_filename = f'data/top_canciones_{pais}.csv'\n",
    "\n",
    "    with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['nombre', 'artista', 'posicion', 'fecha_subida', 'fecha_lanzamiento', 'reproducciones']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for cancion in canciones:\n",
    "            writer.writerow(cancion)\n",
    "\n",
    "    print(f\"Datos almacenados correctamente en '{csv_filename}' para {pais}.\")\n",
    "```\n",
    "\n",
    "Esta función:\n",
    "1. Crea un directorio `data` si no existe.\n",
    "2. Crea y abre un archivo CSV para escribir los datos.\n",
    "3. Escribe los encabezados y la información de cada canción en el archivo CSV.\n",
    "\n",
    "#### 5. Leer los IDs de las Playlists por País\n",
    "\n",
    "```python\n",
    "def leer_ids_pais(filename):\n",
    "    ids_pais = {}\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            if \"=\" in line:\n",
    "                pais, playlist_id = line.strip().split(\" = \")\n",
    "                ids_pais[pais.strip()] = playlist_id.strip()\n",
    "    return ids_pais\n",
    "```\n",
    "\n",
    "Esta función:\n",
    "1. Lee un archivo con IDs de playlists por país.\n",
    "2. Devuelve un diccionario donde las claves son los nombres de los países y los valores son los IDs de las playlists.\n",
    "\n",
    "### Ejecución del Script\n",
    "\n",
    "```python\n",
    "if __name__ == '__main__':\n",
    "    ids_pais = leer_ids_pais('ID_Pais_sp.txt')\n",
    "\n",
    "    for pais, playlist_id in ids_pais.items():\n",
    "        crear_tabla(pais)\n",
    "        canciones = obtener_top_canciones(playlist_id)\n",
    "        almacenar_en_sqlite(canciones, pais)\n",
    "        almacenar_en_csv(canciones, pais)\n",
    "```\n",
    "\n",
    "Este bloque de código:\n",
    "1. Lee los IDs de las playlists desde el archivo `ID_Pais_sp.txt`.\n",
    "2. Para cada país:\n",
    "    - Crea una tabla en SQLite.\n",
    "    - Obtiene las top canciones de la playlist correspondiente.\n",
    "    - Almacena las canciones en la base de datos SQLite.\n",
    "    - Exporta las canciones a un archivo CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aca4ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla 'top_canciones_Perú' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Perú.\n",
      "Datos almacenados correctamente en 'data/top_canciones_Perú.csv' para Perú.\n",
      "Tabla 'top_canciones_Colombia' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Colombia.\n",
      "Datos almacenados correctamente en 'data/top_canciones_Colombia.csv' para Colombia.\n",
      "Tabla 'top_canciones_Argentina' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Argentina.\n",
      "Datos almacenados correctamente en 'data/top_canciones_Argentina.csv' para Argentina.\n",
      "Tabla 'top_canciones_Brasil' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Brasil.\n",
      "Datos almacenados correctamente en 'data/top_canciones_Brasil.csv' para Brasil.\n",
      "Tabla 'top_canciones_Chile' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Chile.\n",
      "Datos almacenados correctamente en 'data/top_canciones_Chile.csv' para Chile.\n",
      "Tabla 'top_canciones_México' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para México.\n",
      "Datos almacenados correctamente en 'data/top_canciones_México.csv' para México.\n",
      "Tabla 'top_canciones_Uruguay' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Uruguay.\n",
      "Datos almacenados correctamente en 'data/top_canciones_Uruguay.csv' para Uruguay.\n",
      "Tabla 'top_canciones_Venezuela' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Venezuela.\n",
      "Datos almacenados correctamente en 'data/top_canciones_Venezuela.csv' para Venezuela.\n",
      "Tabla 'top_canciones_Ecuador' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Ecuador.\n",
      "Datos almacenados correctamente en 'data/top_canciones_Ecuador.csv' para Ecuador.\n",
      "Tabla 'top_canciones_Puerto_Rico' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Puerto_Rico.\n",
      "Datos almacenados correctamente en 'data/top_canciones_Puerto_Rico.csv' para Puerto_Rico.\n",
      "Tabla 'top_canciones_Estados_Unidos' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Estados_Unidos.\n",
      "Datos almacenados correctamente en 'data/top_canciones_Estados_Unidos.csv' para Estados_Unidos.\n",
      "Tabla 'top_canciones_Reino_Unido' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Reino_Unido.\n",
      "Datos almacenados correctamente en 'data/top_canciones_Reino_Unido.csv' para Reino_Unido.\n",
      "Tabla 'top_canciones_Japón' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Japón.\n",
      "Datos almacenados correctamente en 'data/top_canciones_Japón.csv' para Japón.\n",
      "Tabla 'top_canciones_Corea_del_Sur' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Corea_del_Sur.\n",
      "Datos almacenados correctamente en 'data/top_canciones_Corea_del_Sur.csv' para Corea_del_Sur.\n",
      "Tabla 'top_canciones_Francia' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Francia.\n",
      "Datos almacenados correctamente en 'data/top_canciones_Francia.csv' para Francia.\n",
      "Tabla 'top_canciones_Alemania' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Alemania.\n",
      "Datos almacenados correctamente en 'data/top_canciones_Alemania.csv' para Alemania.\n",
      "Tabla 'top_canciones_Australia' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Australia.\n",
      "Datos almacenados correctamente en 'data/top_canciones_Australia.csv' para Australia.\n",
      "Tabla 'top_canciones_Canadá' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para Canadá.\n",
      "Datos almacenados correctamente en 'data/top_canciones_Canadá.csv' para Canadá.\n",
      "Tabla 'top_canciones_India' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para India.\n",
      "Datos almacenados correctamente en 'data/top_canciones_India.csv' para India.\n",
      "Tabla 'top_canciones_España' creada correctamente en SQLite.\n",
      "Datos almacenados correctamente en SQLite para España.\n",
      "Datos almacenados correctamente en 'data/top_canciones_España.csv' para España.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "# Función para obtener las top 50 canciones de una playlist en Spotify\n",
    "def obtener_top_canciones(playlist_id):\n",
    "    # Configurar credenciales de Spotify\n",
    "    with open('spotify_credentials.txt') as f:\n",
    "        lines = f.readlines()\n",
    "        client_id = lines[0].strip()\n",
    "        client_secret = lines[1].strip()\n",
    "\n",
    "    client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "    sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "    # Obtener información de la playlist\n",
    "    playlist = sp.playlist_tracks(playlist_id=playlist_id, limit=50)\n",
    "\n",
    "    # Preparar los datos para la base de datos\n",
    "    canciones = []\n",
    "    for index, track in enumerate(playlist['items'], start=1):\n",
    "        # Obtener la fecha de lanzamiento de la canción\n",
    "        fecha_lanzamiento = track['track']['album']['release_date']\n",
    "        try:\n",
    "            fecha_lanzamiento = datetime.strptime(fecha_lanzamiento, '%Y-%m-%d').date()\n",
    "        except ValueError:\n",
    "            try:\n",
    "                fecha_lanzamiento = datetime.strptime(fecha_lanzamiento, '%Y').date()  # Intenta manejar el caso de solo año\n",
    "            except ValueError:\n",
    "                fecha_lanzamiento = None  # Si no se puede convertir, dejar como None\n",
    "\n",
    "        # Crear el diccionario de la canción\n",
    "        cancion = {\n",
    "            'nombre': track['track']['name'],\n",
    "            'artista': track['track']['artists'][0]['name'],\n",
    "            'posicion': index,  # Usamos el índice + 1 como posición única\n",
    "            'fecha_subida': datetime.now().date(),  # Fecha de subida actual\n",
    "            'fecha_lanzamiento': fecha_lanzamiento,  # Fecha de lanzamiento de la canción\n",
    "            'reproducciones': track['track']['popularity']  # Obtener el número de reproducciones\n",
    "        }\n",
    "        canciones.append(cancion)\n",
    "\n",
    "    return canciones\n",
    "\n",
    "# Función para crear una tabla en SQLite\n",
    "def crear_tabla(pais):\n",
    "    conn = sqlite3.connect('spotify.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        # Crear la tabla si no existe\n",
    "        cursor.execute(f'''\n",
    "            CREATE TABLE IF NOT EXISTS top_canciones_{pais} (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                nombre TEXT,\n",
    "                artista TEXT,\n",
    "                posicion INTEGER,\n",
    "                fecha_subida DATE,\n",
    "                fecha_lanzamiento DATE,\n",
    "                reproducciones INTEGER\n",
    "            )\n",
    "        ''')\n",
    "        conn.commit()\n",
    "        print(f\"Tabla 'top_canciones_{pais}' creada correctamente en SQLite.\")\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Error al crear la tabla: {e}\")\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "# Función para almacenar las canciones en SQLite\n",
    "def almacenar_en_sqlite(canciones, pais):\n",
    "    conn = sqlite3.connect('spotify.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        # Insertar las canciones en la tabla\n",
    "        for cancion in canciones:\n",
    "            cursor.execute(f'''\n",
    "                INSERT INTO top_canciones_{pais}(nombre, artista, posicion, fecha_subida, fecha_lanzamiento, reproducciones)\n",
    "                VALUES (?, ?, ?, ?, ?, ?)\n",
    "            ''', (cancion['nombre'], cancion['artista'], cancion['posicion'], cancion['fecha_subida'], cancion['fecha_lanzamiento'], cancion['reproducciones']))\n",
    "\n",
    "        conn.commit()\n",
    "        print(f\"Datos almacenados correctamente en SQLite para {pais}.\")\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Error al insertar datos: {e}\")\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "# Función para almacenar las canciones en un archivo CSV dentro de la carpeta 'data'\n",
    "def almacenar_en_csv(canciones, pais):\n",
    "    # Crear la carpeta 'data' si no existe\n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "\n",
    "    csv_filename = f'data/top_canciones_{pais}.csv'\n",
    "\n",
    "    with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['nombre', 'artista', 'posicion', 'fecha_subida', 'fecha_lanzamiento', 'reproducciones']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for cancion in canciones:\n",
    "            writer.writerow(cancion)\n",
    "\n",
    "    print(f\"Datos almacenados correctamente en '{csv_filename}' para {pais}.\")\n",
    "\n",
    "# Función para leer los IDs de las playlists por país\n",
    "def leer_ids_pais(filename):\n",
    "    ids_pais = {}\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            if \"=\" in line:\n",
    "                pais, playlist_id = line.strip().split(\" = \")\n",
    "                ids_pais[pais.strip()] = playlist_id.strip()\n",
    "    return ids_pais\n",
    "\n",
    "# Ejemplo de uso\n",
    "if __name__ == '__main__':\n",
    "    ids_pais = leer_ids_pais('ID_Pais_sp.txt')\n",
    "\n",
    "    for pais, playlist_id in ids_pais.items():\n",
    "        crear_tabla(pais)\n",
    "        canciones = obtener_top_canciones(playlist_id)\n",
    "        almacenar_en_sqlite(canciones, pais)\n",
    "        almacenar_en_csv(canciones, pais)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c2634a",
   "metadata": {},
   "source": [
    "## Proceso para los hallar los Artistas de las Top Canciones de Spotify y Top Tendencias musicales de Yotube de un País \n",
    "\n",
    "### Importación de módulos\n",
    "\n",
    "```python\n",
    "import sqlite3\n",
    "import os\n",
    "```\n",
    "\n",
    "- `sqlite3`: Módulo estándar de Python para interactuar con bases de datos SQLite.\n",
    "- `os`: Módulo estándar de Python para realizar operaciones del sistema operativo, como manejo de rutas de archivos.\n",
    "\n",
    "#### Función `find_tables_with_keyword`\n",
    "\n",
    "```python\n",
    "def find_tables_with_keyword(db_path, keyword):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return [table[0] for table in tables if keyword in table[0]]\n",
    "```\n",
    "\n",
    "- **Descripción**: Esta función busca tablas en una base de datos SQLite cuyos nombres contienen un keyword específico.\n",
    "- **Parámetros**:\n",
    "  - `db_path`: Ruta del archivo de la base de datos SQLite.\n",
    "  - `keyword`: Palabra clave para buscar en los nombres de las tablas.\n",
    "- **Retorno**:\n",
    "  - Una lista de nombres de tablas que coinciden con el keyword especificado.\n",
    "\n",
    "#### Función `get_column_names`\n",
    "\n",
    "```python\n",
    "def get_column_names(db_path, table_name):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "    columns = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return [column[1] for column in columns]\n",
    "```\n",
    "\n",
    "- **Descripción**: Esta función obtiene los nombres de las columnas de una tabla específica en una base de datos SQLite.\n",
    "- **Parámetros**:\n",
    "  - `db_path`: Ruta del archivo de la base de datos SQLite.\n",
    "  - `table_name`: Nombre de la tabla de la cual se desean obtener los nombres de las columnas.\n",
    "- **Retorno**:\n",
    "  - Una lista de nombres de columnas de la tabla especificada.\n",
    "\n",
    "#### Función `extract_columns`\n",
    "\n",
    "```python\n",
    "def extract_columns(db_path, table_name, column_indices):ne\n",
    "    column_names = get_column_names(db_path, table_name)\n",
    "    columns_to_extract = [column_names[idx] for idx in column_indices]\n",
    "    \n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        query = f\"SELECT {', '.join(columns_to_extract)} FROM {table_name}\"\n",
    "        cursor.execute(query)\n",
    "        rows = cursor.fetchall()\n",
    "        \n",
    "        print(f\"\\nDatos de la tabla {table_name} en {os.path.basename(db_path)}:\")\n",
    "        for row in rows:\n",
    "            for i, col in enumerate(columns_to_extract):\n",
    "                print(f\"{col}: {row[i]}\")\n",
    "            print()  # Nueva línea entre registros\n",
    "    except sqlite3.OperationalError as e:\n",
    "        print(f\"Error en la tabla {table_name}: {e}\")\n",
    "    conn.close()\n",
    "```\n",
    "\n",
    "- **Descripción**: Esta función extrae columnas específicas de una tabla en la base de datos SQLite y las imprime.\n",
    "- **Parámetros**:\n",
    "  - `db_path`: Ruta del archivo de la base de datos SQLite.\n",
    "  - `table_name`: Nombre de la tabla de la cual se extraerán las columnas.\n",
    "  - `column_indices`: Lista de índices de las columnas que se deben extraer.\n",
    "- **Retorno**:\n",
    "  - No retorna ningún valor explícito, imprime los datos extraídos de la tabla.\n",
    "\n",
    "#### Función `main`\n",
    "\n",
    "```python\n",
    "def main():\n",
    "    keyword = input(\"Ingresa el nombre que deseas buscar en las tablas (por ejemplo, 'Perú'): \")\n",
    "\n",
    "    # Lista de bases de datos a revisar con columnas específicas a extraer\n",
    "    databases = {\n",
    "        'spotify.db': [2, 4],  # Columnas a extraer de Spotify: tercera (2) y quinta (4)\n",
    "        'youtube.db': [2, 4]   # Columnas a extraer de YouTube Music: tercera (2) y quinta (4)\n",
    "    }\n",
    "\n",
    "    db_folder_path = '.'  # Ruta de la carpeta donde están las bases de datos\n",
    "\n",
    "    # Iterar sobre cada base de datos y buscar tablas con el keyword\n",
    "    for db_name, column_indices in databases.items():\n",
    "        db_path = os.path.join(db_folder_path, db_name)\n",
    "        print(f\"\\nBuscando en la base de datos: {db_name}\")\n",
    "        \n",
    "        tables = find_tables_with_keyword(db_path, keyword)\n",
    "        if tables:\n",
    "            for table in tables:\n",
    "                extract_columns(db_path, table, column_indices)\n",
    "        else:\n",
    "            print(f\"No se encontraron tablas con '{keyword}' en la base de datos {db_name}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```\n",
    "\n",
    "- **Descripción**: Función principal del script que ejecuta el proceso de búsqueda y extracción de datos.\n",
    "- **Acciones**:\n",
    "  - Solicita al usuario un keyword para buscar en los nombres de las tablas.\n",
    "  - Define una lista de bases de datos con columnas específicas a extraer.\n",
    "  - Itera sobre cada base de datos, busca tablas que contengan el keyword y extrae las columnas especificadas.\n",
    "- **Retorno**:\n",
    "  - No retorna ningún valor explícito, muestra los datos encontrados en las tablas que cumplen con el criterio de búsqueda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbc1296d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Buscando en la base de datos: spotify.db\n",
      "\n",
      "Datos de la tabla top_canciones_Venezuela en spotify.db:\n",
      "artista: KAROL G\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Feid\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Blessd\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Trueno\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Boza\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Rvssian\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Feid\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: KAROL G\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Feid\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: J Abdiel\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: FloyyMenor\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Plan B\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Steven Vitali\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Bad Bunny\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Jimin\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: KAROL G\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Rawayana\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Kapo\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: KAROL G\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Alvaro Diaz\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Manuel Turizo\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Omar Courtz\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Myke Towers\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Young Miko\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Feid\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Rauw Alejandro\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Feid\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: iZaak\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: YOVNGCHIMI\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Quevedo\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Beéle\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Rawayana\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Mora\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: The Academy: Segunda Misión\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Marshmello\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Eusebio\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Rawayana\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Myke Towers\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Feid\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Sabrina Carpenter\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Sabrina Carpenter\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: J Balvin\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Cris Mj\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Camilo\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: KAROL G\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: ELENA ROSE\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: KAROL G\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Rawayana\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Danny Ocean\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "artista: Jimin\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "\n",
      "Buscando en la base de datos: youtube.db\n",
      "\n",
      "Datos de la tabla top_tendencias_Venezuela en youtube.db:\n",
      "canal: Gigi Méndez\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "canal: KarolGVEVO\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "canal: J abdiel\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "canal: Caribbean Breeze\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "canal: Anuel AA\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "canal: Manuel Santos - Topic\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "canal: ElAlfaElJefeTV\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "canal: LLOUD Official\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "canal: Sevdaliza\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "canal: Latin Union\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "canal: SLAYTER\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "canal: KendrickLamarVEVO\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "canal: Myke Towers\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "canal: Miguel Bueno\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "canal: GreeicyVEVO\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "canal: Dj Francisco Freites\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "canal: Big One\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "canal: Eterna Vida\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "canal: Junior Caldera\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "canal: Lomiiel - Topic\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "canal: Alex Ponce\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "canal: Dejavu FF\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "canal: LLOUD Official\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "canal: Servando y Florentino\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "canal: TWICE JAPAN OFFICIAL YouTube Channel\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "canal: Clarent\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "canal: HYBE LABELS\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "canal: Luar La L \n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "canal: magnificent\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "canal: BANGTANTV\n",
      "fecha_subida: 2024-07-10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "\n",
    "def find_tables_with_keyword(db_path, keyword):\n",
    "    \"\"\"Encuentra tablas en la base de datos cuyo nombre contiene el keyword.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return [table[0] for table in tables if keyword in table[0]]\n",
    "\n",
    "def get_column_names(db_path, table_name):\n",
    "    \"\"\"Obtiene los nombres de las columnas de una tabla.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "    columns = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return [column[1] for column in columns]\n",
    "\n",
    "def extract_columns(db_path, table_name, column_indices):\n",
    "    \"\"\"Extrae columnas específicas de una tabla.\"\"\"\n",
    "    column_names = get_column_names(db_path, table_name)\n",
    "    columns_to_extract = [column_names[idx] for idx in column_indices]\n",
    "    \n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        query = f\"SELECT {', '.join(columns_to_extract)} FROM {table_name}\"\n",
    "        cursor.execute(query)\n",
    "        rows = cursor.fetchall()\n",
    "        \n",
    "        print(f\"\\nDatos de la tabla {table_name} en {os.path.basename(db_path)}:\")\n",
    "        for row in rows:\n",
    "            for i, col in enumerate(columns_to_extract):\n",
    "                print(f\"{col}: {row[i]}\")\n",
    "            print()  # Nueva línea entre registros\n",
    "    except sqlite3.OperationalError as e:\n",
    "        print(f\"Error en la tabla {table_name}: {e}\")\n",
    "    conn.close()\n",
    "\n",
    "def main():\n",
    "    keyword = input(\"Ingresa el nombre que deseas buscar en las tablas (por ejemplo, 'Perú'): \")\n",
    "\n",
    "    # Lista de bases de datos a revisar\n",
    "    databases = {\n",
    "        'spotify.db': [2, 4],  # Columnas a extraer de Spotify: tercera (2) y quinta (4)\n",
    "        'youtube.db': [2, 4]   # Columnas a extraer de YouTube Music: tercera (2) y quinta (4)\n",
    "    }\n",
    "\n",
    "    db_folder_path = '.'  # Ajusta esto a la ruta correcta si es necesario\n",
    "\n",
    "    for db_name, column_indices in databases.items():\n",
    "        db_path = os.path.join(db_folder_path, db_name)\n",
    "        print(f\"\\nBuscando en la base de datos: {db_name}\")\n",
    "        \n",
    "        tables = find_tables_with_keyword(db_path, keyword)\n",
    "        if tables:\n",
    "            for table in tables:\n",
    "                extract_columns(db_path, table, column_indices)\n",
    "        else:\n",
    "            print(f\"No se encontraron tablas con '{keyword}' en la base de datos {db_name}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc1c6d4",
   "metadata": {},
   "source": [
    "## Búsqueda y Comparación de Tablas en la Base de Datos de Spotify\n",
    "\n",
    "El siguiente script Python realiza la búsqueda y comparación de las primeras filas de tablas en una base de datos SQLite, basado en palabras clave ingresadas por el usuario.\n",
    "\n",
    "#### Importación de Módulos\n",
    "\n",
    "```python\n",
    "import sqlite3\n",
    "import os\n",
    "```\n",
    "\n",
    "- **Descripción**: Se importan los módulos necesarios para interactuar con SQLite y manejar operaciones del sistema operativo.\n",
    "\n",
    "#### Función `find_table_with_keyword`\n",
    "\n",
    "```python\n",
    "def find_table_with_keyword(db_path, keyword):\n",
    "    \"\"\"\n",
    "    Encuentra la primera tabla en la base de datos cuyo nombre contiene el keyword especificado.\n",
    "\n",
    "    Parameters:\n",
    "    - db_path (str): Ruta del archivo de la base de datos SQLite.\n",
    "    - keyword (str): Palabra clave para buscar en los nombres de las tablas.\n",
    "\n",
    "    Returns:\n",
    "    - str or None: Nombre de la primera tabla que contiene el keyword, o None si no se encuentra ninguna.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    conn.close()\n",
    "    for table in tables:\n",
    "        if keyword in table[0]:\n",
    "            return table[0]\n",
    "    return None\n",
    "```\n",
    "\n",
    "- **Descripción**: Esta función encuentra la primera tabla en la base de datos cuyo nombre contiene el keyword especificado.\n",
    "- **Parámetros**:\n",
    "  - `db_path`: Ruta del archivo de la base de datos SQLite.\n",
    "  - `keyword`: Palabra clave para buscar en los nombres de las tablas.\n",
    "- **Retorno**:\n",
    "  - Retorna el nombre de la primera tabla que contiene el keyword o None si no se encuentra ninguna tabla que coincida.\n",
    "\n",
    "#### Función `get_column_names`\n",
    "\n",
    "```python\n",
    "def get_column_names(db_path, table_name):\n",
    "    \"\"\"\n",
    "    Obtiene los nombres de las columnas de una tabla en la base de datos SQLite.\n",
    "\n",
    "    Parameters:\n",
    "    - db_path (str): Ruta del archivo de la base de datos SQLite.\n",
    "    - table_name (str): Nombre de la tabla de la cual se obtendrán los nombres de las columnas.\n",
    "\n",
    "    Returns:\n",
    "    - list: Lista de nombres de columnas de la tabla especificada.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "    columns = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return [column[1] for column in columns]\n",
    "```\n",
    "\n",
    "- **Descripción**: Esta función obtiene los nombres de las columnas de una tabla específica en la base de datos SQLite.\n",
    "- **Parámetros**:\n",
    "  - `db_path`: Ruta del archivo de la base de datos SQLite.\n",
    "  - `table_name`: Nombre de la tabla de la cual se desean obtener los nombres de las columnas.\n",
    "- **Retorno**:\n",
    "  - Retorna una lista de nombres de columnas de la tabla especificada.\n",
    "\n",
    "#### Función `extract_first_row`\n",
    "\n",
    "```python\n",
    "def extract_first_row(db_path, table_name, column_indices):\n",
    "    \"\"\"\n",
    "    Extrae la primera fila de columnas específicas de una tabla en la base de datos SQLite.\n",
    "\n",
    "    Parameters:\n",
    "    - db_path (str): Ruta del archivo de la base de datos SQLite.\n",
    "    - table_name (str): Nombre de la tabla de la cual se extraerá la primera fila.\n",
    "    - column_indices (list): Índices de las columnas que se deben extraer.\n",
    "\n",
    "    Returns:\n",
    "    - dict or None: Diccionario con los datos de la primera fila, o None si no se encuentra ninguna fila.\n",
    "    \"\"\"\n",
    "    column_names = get_column_names(db_path, table_name)\n",
    "    columns_to_extract = [column_names[idx] for idx in column_indices]\n",
    "    \n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        query = f\"SELECT {', '.join(columns_to_extract)} FROM {table_name} LIMIT 1\"\n",
    "        cursor.execute(query)\n",
    "        row = cursor.fetchone()\n",
    "        if row:\n",
    "            return {columns_to_extract[i]: row[i] for i in range(len(row))}\n",
    "        else:\n",
    "            return None\n",
    "    except sqlite3.OperationalError as e:\n",
    "        print(f\"Error en la tabla {table_name}: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        conn.close()\n",
    "```\n",
    "\n",
    "- **Descripción**: Esta función extrae la primera fila de columnas específicas de una tabla en la base de datos SQLite y retorna los datos en forma de diccionario.\n",
    "- **Parámetros**:\n",
    "  - `db_path`: Ruta del archivo de la base de datos SQLite.\n",
    "  - `table_name`: Nombre de la tabla de la cual se desea extraer la primera fila.\n",
    "  - `column_indices`: Lista de índices de las columnas que se deben extraer.\n",
    "- **Retorno**:\n",
    "  - Retorna un diccionario con los datos de la primera fila, o None si no se encuentra ninguna fila.\n",
    "\n",
    "#### Función `main`\n",
    "\n",
    "```python\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Función principal del script. Solicita al usuario dos palabras clave,\n",
    "    busca las tablas correspondientes en la base de datos y compara las primeras filas de datos.\n",
    "    \"\"\"\n",
    "    keyword1 = input(\"Ingresa la primera palabra clave para buscar en las tablas: \")\n",
    "    keyword2 = input(\"Ingresa la segunda palabra clave para buscar en las tablas: \")\n",
    "\n",
    "    db_name = 'spotify.db'  # Nombre de la base de datos\n",
    "    column_indices = [2, 4]  # Índices de las columnas a extraer: tercera (2) y quinta (4)\n",
    "\n",
    "    db_path = os.path.join('.', db_name)  # Ruta de la base de datos (ajusta según sea necesario)\n",
    "\n",
    "    table1 = find_table_with_keyword(db_path, keyword1)\n",
    "    table2 = find_table_with_keyword(db_path, keyword2)\n",
    "\n",
    "    if table1 and table2:\n",
    "        print(f\"\\nTabla encontrada para '{keyword1}': {table1}\")\n",
    "        print(f\"Tabla encontrada para '{keyword2}': {table2}\")\n",
    "\n",
    "        row1 = extract_first_row(db_path, table1, column_indices)\n",
    "        row2 = extract_first_row(db_path, table2, column_indices)\n",
    "\n",
    "        if row1 and row2:\n",
    "            print(\"\\nComparando las primeras filas de las tablas seleccionadas:\")\n",
    "            print(f\"Datos de la primera fila de la tabla {table1}:\")\n",
    "            for col, val in row1.items():\n",
    "                print(f\"{col}: {val}\")\n",
    "\n",
    "            print(f\"\\nDatos de la primera fila de la tabla {table2}:\")\n",
    "            for col, val in row2.items():\n",
    "                print(f\"{col}: {val}\")\n",
    "        else:\n",
    "            print(\"No se encontraron datos en una o ambas tablas.\")\n",
    "    else:\n",
    "        if not table1:\n",
    "            print(f\"No se encontró ninguna tabla con '{keyword1}' en la base de datos {db_name}.\")\n",
    "        if not table2:\n",
    "            print(f\"No se encontró ninguna tabla con '{keyword2}' en la base de datos {db_name}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```\n",
    "\n",
    "- **Descripción**: Función principal del script que realiza la búsqueda y comparación de las primeras filas de tablas en la base de datos SQLite.\n",
    "- **Acciones**:\n",
    "  - Solicita al usuario dos palabras clave para buscar en los nombres de las tablas.\n",
    "  - Encuentra las tablas correspondientes en la base de datos.\n",
    "  - Extrae y compara las primeras filas de datos de las tablas encontradas.\n",
    "- **Retorno**:\n",
    "  - No retorna ningún valor explícito, muestra los resultados de la búsqueda y comparación en la consola."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31c7cd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tabla encontrada para 'Pe': top_canciones_Perú\n",
      "Tabla encontrada para 'Vene': top_canciones_Venezuela\n",
      "\n",
      "Comparando las primeras filas de las tablas seleccionadas:\n",
      "Datos de la primera fila de la tabla top_canciones_Perú:\n",
      "artista: Trueno\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "Datos de la primera fila de la tabla top_canciones_Venezuela:\n",
      "artista: KAROL G\n",
      "fecha_subida: 2024-07-10\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "\n",
    "def find_table_with_keyword(db_path, keyword):\n",
    "    \"\"\"Encuentra la primera tabla en la base de datos cuyo nombre contiene el keyword.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    conn.close()\n",
    "    for table in tables:\n",
    "        if keyword in table[0]:\n",
    "            return table[0]\n",
    "    return None\n",
    "\n",
    "def get_column_names(db_path, table_name):\n",
    "    \"\"\"Obtiene los nombres de las columnas de una tabla.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "    columns = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return [column[1] for column in columns]\n",
    "\n",
    "def extract_first_row(db_path, table_name, column_indices):\n",
    "    \"\"\"Extrae la primera fila de columnas específicas de una tabla.\"\"\"\n",
    "    column_names = get_column_names(db_path, table_name)\n",
    "    columns_to_extract = [column_names[idx] for idx in column_indices]\n",
    "    \n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        query = f\"SELECT {', '.join(columns_to_extract)} FROM {table_name} LIMIT 1\"\n",
    "        cursor.execute(query)\n",
    "        row = cursor.fetchone()\n",
    "        if row:\n",
    "            return {columns_to_extract[i]: row[i] for i in range(len(row))}\n",
    "        else:\n",
    "            return None\n",
    "    except sqlite3.OperationalError as e:\n",
    "        print(f\"Error en la tabla {table_name}: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "def main():\n",
    "    keyword1 = input(\"Ingresa la primera palabra clave para buscar en las tablas: \")\n",
    "    keyword2 = input(\"Ingresa la segunda palabra clave para buscar en las tablas: \")\n",
    "\n",
    "    # Base de datos y columnas a extraer\n",
    "    db_name = 'spotify.db'\n",
    "    column_indices = [2, 4]  # Tercera (2) y quinta (4) columnas\n",
    "\n",
    "    db_path = os.path.join('.', db_name)  # Ajusta esto a la ruta correcta si es necesario\n",
    "\n",
    "    # Encuentra las tablas correspondientes a cada palabra clave\n",
    "    table1 = find_table_with_keyword(db_path, keyword1)\n",
    "    table2 = find_table_with_keyword(db_path, keyword2)\n",
    "\n",
    "    if table1 and table2:\n",
    "        print(f\"\\nTabla encontrada para '{keyword1}': {table1}\")\n",
    "        print(f\"Tabla encontrada para '{keyword2}': {table2}\")\n",
    "\n",
    "        row1 = extract_first_row(db_path, table1, column_indices)\n",
    "        row2 = extract_first_row(db_path, table2, column_indices)\n",
    "\n",
    "        if row1 and row2:\n",
    "            print(\"\\nComparando las primeras filas de las tablas seleccionadas:\")\n",
    "            print(f\"Datos de la primera fila de la tabla {table1}:\")\n",
    "            for col, val in row1.items():\n",
    "                print(f\"{col}: {val}\")\n",
    "\n",
    "            print(f\"\\nDatos de la primera fila de la tabla {table2}:\")\n",
    "            for col, val in row2.items():\n",
    "                print(f\"{col}: {val}\")\n",
    "        else:\n",
    "            print(\"No se encontraron datos en una o ambas tablas.\")\n",
    "    else:\n",
    "        if not table1:\n",
    "            print(f\"No se encontró ninguna tabla con '{keyword1}' en la base de datos {db_name}.\")\n",
    "        if not table2:\n",
    "            print(f\"No se encontró ninguna tabla con '{keyword2}' en la base de datos {db_name}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b8258a",
   "metadata": {},
   "source": [
    "## Búsqueda y Comparación de Tablas en la Base de Datos de YouTube Music\n",
    "\n",
    "El siguiente script Python permite buscar y comparar las primeras filas de tablas en la base de datos de YouTube Music, utilizando palabras clave ingresadas por el usuario.\n",
    "\n",
    "#### Importación de Módulos\n",
    "\n",
    "```python\n",
    "import sqlite3\n",
    "import os\n",
    "```\n",
    "\n",
    "- **Descripción**: Se importan los módulos necesarios para interactuar con SQLite y manejar operaciones del sistema operativo.\n",
    "\n",
    "#### Función `find_table_with_keyword`\n",
    "\n",
    "```python\n",
    "def find_table_with_keyword(db_path, keyword):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    conn.close()\n",
    "    for table in tables:\n",
    "        if keyword in table[0]:\n",
    "            return table[0]\n",
    "    return None\n",
    "```\n",
    "\n",
    "- **Descripción**: Esta función encuentra la primera tabla en la base de datos de YouTube Music cuyo nombre contiene el keyword especificado.\n",
    "- **Parámetros**:\n",
    "  - `db_path`: Ruta del archivo de la base de datos SQLite.\n",
    "  - `keyword`: Palabra clave para buscar en los nombres de las tablas.\n",
    "- **Retorno**:\n",
    "  - Retorna el nombre de la primera tabla que contiene el keyword o None si no se encuentra ninguna tabla que coincida.\n",
    "\n",
    "#### Función `get_column_names`\n",
    "\n",
    "```python\n",
    "def get_column_names(db_path, table_name):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "    columns = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return [column[1] for column in columns]\n",
    "```\n",
    "\n",
    "- **Descripción**: Esta función obtiene los nombres de las columnas de una tabla específica en la base de datos SQLite de YouTube Music.\n",
    "- **Parámetros**:\n",
    "  - `db_path`: Ruta del archivo de la base de datos SQLite.\n",
    "  - `table_name`: Nombre de la tabla de la cual se desean obtener los nombres de las columnas.\n",
    "- **Retorno**:\n",
    "  - Retorna una lista de nombres de columnas de la tabla especificada.\n",
    "\n",
    "#### Función `extract_first_row`\n",
    "\n",
    "```python\n",
    "def extract_first_row(db_path, table_name, column_indices):\n",
    "    column_names = get_column_names(db_path, table_name)\n",
    "    columns_to_extract = [column_names[idx] for idx in column_indices]\n",
    "    \n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        query = f\"SELECT {', '.join(columns_to_extract)} FROM {table_name} LIMIT 1\"\n",
    "        cursor.execute(query)\n",
    "        row = cursor.fetchone()\n",
    "        if row:\n",
    "            return {columns_to_extract[i]: row[i] for i in range(len(row))}\n",
    "        else:\n",
    "            return None\n",
    "    except sqlite3.OperationalError as e:\n",
    "        print(f\"Error en la tabla {table_name}: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        conn.close()\n",
    "```\n",
    "\n",
    "- **Descripción**: Esta función extrae la primera fila de columnas específicas de una tabla en la base de datos SQLite de YouTube Music y retorna los datos en forma de diccionario.\n",
    "- **Parámetros**:\n",
    "  - `db_path`: Ruta del archivo de la base de datos SQLite.\n",
    "  - `table_name`: Nombre de la tabla de la cual se desea extraer la primera fila.\n",
    "  - `column_indices`: Lista de índices de las columnas que se deben extraer.\n",
    "- **Retorno**:\n",
    "  - Retorna un diccionario con los datos de la primera fila, o None si no se encuentra ninguna fila.\n",
    "\n",
    "#### Función `main`\n",
    "\n",
    "```python\n",
    "def main():\n",
    "    keyword1 = input(\"Ingresa la primera palabra clave para buscar en las tablas de YouTube Music: \")\n",
    "    keyword2 = input(\"Ingresa la segunda palabra clave para buscar en las tablas de YouTube Music: \")\n",
    "\n",
    "    db_name = 'youtube.db'  # Nombre de la base de datos\n",
    "    column_indices = [2, 4]  # Índices de las columnas a extraer: tercera (2) y quinta (4)\n",
    "\n",
    "    db_path = os.path.join('.', db_name)  # Ruta de la base de datos (ajusta según sea necesario)\n",
    "\n",
    "    table1 = find_table_with_keyword(db_path, keyword1)\n",
    "    table2 = find_table_with_keyword(db_path, keyword2)\n",
    "\n",
    "    if table1 and table2:\n",
    "        print(f\"\\nTabla encontrada para '{keyword1}': {table1}\")\n",
    "        print(f\"Tabla encontrada para '{keyword2}': {table2}\")\n",
    "\n",
    "        row1 = extract_first_row(db_path, table1, column_indices)\n",
    "        row2 = extract_first_row(db_path, table2, column_indices)\n",
    "\n",
    "        if row1 and row2:\n",
    "            print(\"\\nComparando las primeras filas de las tablas seleccionadas:\")\n",
    "            print(f\"Datos de la primera fila de la tabla {table1}:\")\n",
    "            for col, val in row1.items():\n",
    "                print(f\"{col}: {val}\")\n",
    "\n",
    "            print(f\"\\nDatos de la primera fila de la tabla {table2}:\")\n",
    "            for col, val in row2.items():\n",
    "                print(f\"{col}: {val}\")\n",
    "        else:\n",
    "            print(\"No se encontraron datos en una o ambas tablas.\")\n",
    "    else:\n",
    "        if not table1:\n",
    "            print(f\"No se encontró ninguna tabla con '{keyword1}' en la base de datos {db_name}.\")\n",
    "        if not table2:\n",
    "            print(f\"No se encontró ninguna tabla con '{keyword2}' en la base de datos {db_name}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```\n",
    "\n",
    "- **Descripción**: Función principal del script que realiza la búsqueda y comparación de las primeras filas de tablas en la base de datos de YouTube Music.\n",
    "- **Acciones**:\n",
    "  - Solicita al usuario dos palabras clave para buscar en los nombres de las tablas.\n",
    "  - Encuentra las tablas correspondientes en la base de datos.\n",
    "  - Extrae y compara las primeras filas de datos de las tablas encontradas.\n",
    "- **Retorno**:\n",
    "  - No retorna ningún valor explícito, muestra los resultados de la búsqueda y comparación en la consola."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87ad99f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tabla encontrada para 'Pe': top_tendencias_Perú\n",
      "Tabla encontrada para 'Vene': top_tendencias_Venezuela\n",
      "\n",
      "Comparando las primeras filas de las tablas seleccionadas:\n",
      "Datos de la primera fila de la tabla top_tendencias_Perú:\n",
      "canal: Caribbean Breeze\n",
      "fecha_subida: 2024-07-10\n",
      "\n",
      "Datos de la primera fila de la tabla top_tendencias_Venezuela:\n",
      "canal: Gigi Méndez\n",
      "fecha_subida: 2024-07-10\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "\n",
    "def find_table_with_keyword(db_path, keyword):\n",
    "    \"\"\"Encuentra la primera tabla en la base de datos cuyo nombre contiene el keyword.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    conn.close()\n",
    "    for table in tables:\n",
    "        if keyword in table[0]:\n",
    "            return table[0]\n",
    "    return None\n",
    "\n",
    "def get_column_names(db_path, table_name):\n",
    "    \"\"\"Obtiene los nombres de las columnas de una tabla.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "    columns = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return [column[1] for column in columns]\n",
    "\n",
    "def extract_first_row(db_path, table_name, column_indices):\n",
    "    \"\"\"Extrae la primera fila de columnas específicas de una tabla.\"\"\"\n",
    "    column_names = get_column_names(db_path, table_name)\n",
    "    columns_to_extract = [column_names[idx] for idx in column_indices]\n",
    "    \n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        query = f\"SELECT {', '.join(columns_to_extract)} FROM {table_name} LIMIT 1\"\n",
    "        cursor.execute(query)\n",
    "        row = cursor.fetchone()\n",
    "        if row:\n",
    "            return {columns_to_extract[i]: row[i] for i in range(len(row))}\n",
    "        else:\n",
    "            return None\n",
    "    except sqlite3.OperationalError as e:\n",
    "        print(f\"Error en la tabla {table_name}: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "def main():\n",
    "    keyword1 = input(\"Ingresa la primera palabra clave para buscar en las tablas de YouTube Music: \")\n",
    "    keyword2 = input(\"Ingresa la segunda palabra clave para buscar en las tablas de YouTube Music: \")\n",
    "\n",
    "    # Base de datos y columnas a extraer\n",
    "    db_name = 'youtube.db'\n",
    "    column_indices = [2, 4]  # Tercera (2) y quinta (4) columnas\n",
    "\n",
    "    db_path = os.path.join('.', db_name)  # Ajusta esto a la ruta correcta si es necesario\n",
    "\n",
    "    # Encuentra las tablas correspondientes a cada palabra clave\n",
    "    table1 = find_table_with_keyword(db_path, keyword1)\n",
    "    table2 = find_table_with_keyword(db_path, keyword2)\n",
    "\n",
    "    if table1 and table2:\n",
    "        print(f\"\\nTabla encontrada para '{keyword1}': {table1}\")\n",
    "        print(f\"Tabla encontrada para '{keyword2}': {table2}\")\n",
    "\n",
    "        row1 = extract_first_row(db_path, table1, column_indices)\n",
    "        row2 = extract_first_row(db_path, table2, column_indices)\n",
    "\n",
    "        if row1 and row2:\n",
    "            print(\"\\nComparando las primeras filas de las tablas seleccionadas:\")\n",
    "            print(f\"Datos de la primera fila de la tabla {table1}:\")\n",
    "            for col, val in row1.items():\n",
    "                print(f\"{col}: {val}\")\n",
    "\n",
    "            print(f\"\\nDatos de la primera fila de la tabla {table2}:\")\n",
    "            for col, val in row2.items():\n",
    "                print(f\"{col}: {val}\")\n",
    "        else:\n",
    "            print(\"No se encontraron datos en una o ambas tablas.\")\n",
    "    else:\n",
    "        if not table1:\n",
    "            print(f\"No se encontró ninguna tabla con '{keyword1}' en la base de datos {db_name}.\")\n",
    "        if not table2:\n",
    "            print(f\"No se encontró ninguna tabla con '{keyword2}' en la base de datos {db_name}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adba8b5a",
   "metadata": {},
   "source": [
    "# Estructura Básica del Documento HTML\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbf64d5-70bc-41fd-91c9-dcb09105d6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
